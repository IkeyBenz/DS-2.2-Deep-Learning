{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train a CNN+MLP deep learning model with Keras with two followings for MNIST dataset:\n",
    "```\n",
    "1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "3. MaxPooling2D(pool_size=(2, 2))\n",
    "4. Dense(128, activation='relu')\n",
    "5. Dense(num_classes, activation='softmax')\n",
    "```\n",
    "Also build another model with BatchNormalization and Dropout. \n",
    "Compare these two models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models:\n",
    "simple_clf = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "advanced_clf = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "simple_clf.compile(optimizer='adam', \n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "advanced_clf.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datas:\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Scale datas to be between 0-1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.1171 - acc: 0.9633\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0369 - acc: 0.9884\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0223 - acc: 0.9927\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 176s 3ms/step - loss: 0.0114 - acc: 0.9958\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 0.1128 - acc: 0.9673\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0453 - acc: 0.9862\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0326 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0177 - acc: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1271df128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train CNN:\n",
    "simple_clf.fit(x_train, y_train, epochs=5)\n",
    "advanced_clf.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 714us/step\n",
      "[0.03337394047673879, 0.991]\n",
      "10000/10000 [==============================] - 7s 728us/step\n",
      "[0.037488482892268804, 0.9896]\n"
     ]
    }
   ],
   "source": [
    "print(simple_clf.evaluate(x_test, y_test))\n",
    "print(advanced_clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lol the simple one is better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
